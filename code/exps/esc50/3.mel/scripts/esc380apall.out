80
(2000, 7)
audio_files length:2000
loadin mel-spectograms..
features are loaded
cpu
model initialized...
attempt is already initialized
Experiment's _80 attempt no_ : 2
Train started..

Epoch - 1 Train-Loss : 3.7548618268966676

Epoch - 1 Valid-Loss : 3.5616719341278076
micro_f1_1 = 0.165 
macro_f1_1 = 0.10866575586776335 

Epoch - 2 Train-Loss : 3.39005259513855

Epoch - 2 Valid-Loss : 3.2288543033599852
micro_f1_2 = 0.265 
macro_f1_2 = 0.20155252600413223 

Epoch - 3 Train-Loss : 3.0445308589935305

Epoch - 3 Valid-Loss : 2.91911545753479
micro_f1_3 = 0.33 
macro_f1_3 = 0.27259530476951394 

Epoch - 4 Train-Loss : 2.7536589765548705

Epoch - 4 Valid-Loss : 2.6881151962280274
micro_f1_4 = 0.4125 
macro_f1_4 = 0.353104695822915 

Epoch - 5 Train-Loss : 2.5275227499008177

Epoch - 5 Valid-Loss : 2.5304357051849364
micro_f1_5 = 0.415 
macro_f1_5 = 0.36273710951121013 

Epoch - 6 Train-Loss : 2.321510297060013

Epoch - 6 Valid-Loss : 2.3796563243865965
micro_f1_6 = 0.46 
macro_f1_6 = 0.41674104340661516 

Epoch - 7 Train-Loss : 2.153517463207245

Epoch - 7 Valid-Loss : 2.2897922563552857
micro_f1_7 = 0.46 
macro_f1_7 = 0.41774849041567313 

Epoch - 8 Train-Loss : 1.990417914390564

Epoch - 8 Valid-Loss : 2.1531216955184935
micro_f1_8 = 0.4875 
macro_f1_8 = 0.46053679073577447 

Epoch - 9 Train-Loss : 1.857681404352188

Epoch - 9 Valid-Loss : 2.039865827560425
micro_f1_9 = 0.51 
macro_f1_9 = 0.48009340709115006 

Epoch - 10 Train-Loss : 1.7361080384254455

Epoch - 10 Valid-Loss : 1.9726333045959472
micro_f1_10 = 0.505 
macro_f1_10 = 0.4731887583774153 

Epoch - 11 Train-Loss : 1.6036951529979706

Epoch - 11 Valid-Loss : 1.8820296001434327
micro_f1_11 = 0.5325 
macro_f1_11 = 0.49666046921774476 

Epoch - 12 Train-Loss : 1.5351050126552581

Epoch - 12 Valid-Loss : 1.8393123865127563
micro_f1_12 = 0.555 
macro_f1_12 = 0.523895937739591 

Epoch - 13 Train-Loss : 1.4358903795480729

Epoch - 13 Valid-Loss : 1.7655187368392944
micro_f1_13 = 0.55 
macro_f1_13 = 0.5142528604118994 

Epoch - 14 Train-Loss : 1.3391623264551162

Epoch - 14 Valid-Loss : 1.7304739189147949
micro_f1_14 = 0.5575 
macro_f1_14 = 0.531976492650796 

Epoch - 15 Train-Loss : 1.2601683127880097

Epoch - 15 Valid-Loss : 1.6770962190628051
micro_f1_15 = 0.585 
macro_f1_15 = 0.5556459581583421 

Epoch - 16 Train-Loss : 1.1969117373228073

Epoch - 16 Valid-Loss : 1.662986264228821
micro_f1_16 = 0.5825 
macro_f1_16 = 0.5509194809542771 

Epoch - 17 Train-Loss : 1.1343626254796981

Epoch - 17 Valid-Loss : 1.6052932810783387
micro_f1_17 = 0.6125 
macro_f1_17 = 0.5840711029297649 

Epoch - 18 Train-Loss : 1.068540913462639

Epoch - 18 Valid-Loss : 1.5109569072723388
micro_f1_18 = 0.61 
macro_f1_18 = 0.5862391236663009 

Epoch - 19 Train-Loss : 0.9961047035455703

Epoch - 19 Valid-Loss : 1.5096288800239563
micro_f1_19 = 0.615 
macro_f1_19 = 0.5930145489185737 

Epoch - 20 Train-Loss : 0.9579405170679093

Epoch - 20 Valid-Loss : 1.4707213640213013
micro_f1_20 = 0.63 
macro_f1_20 = 0.6126526808245074 

Epoch - 21 Train-Loss : 0.9148812526464463

Epoch - 21 Valid-Loss : 1.47065279006958
micro_f1_21 = 0.62 
macro_f1_21 = 0.5932737625590634 

Epoch - 22 Train-Loss : 0.8583762443065643

Epoch - 22 Valid-Loss : 1.4474740433692932
micro_f1_22 = 0.625 
macro_f1_22 = 0.6035092883664697 

Epoch - 23 Train-Loss : 0.8206111079454422

Epoch - 23 Valid-Loss : 1.3689293670654297
micro_f1_23 = 0.6325 
macro_f1_23 = 0.6129485460322719 

Epoch - 24 Train-Loss : 0.7925217181444169

Epoch - 24 Valid-Loss : 1.3394566321372985
micro_f1_24 = 0.6475 
macro_f1_24 = 0.6246688997650769 

Epoch - 25 Train-Loss : 0.7393005329370499

Epoch - 25 Valid-Loss : 1.3280291748046875
micro_f1_25 = 0.665 
macro_f1_25 = 0.6444767959191166 

Epoch - 26 Train-Loss : 0.709051795899868

Epoch - 26 Valid-Loss : 1.3227999806404114
micro_f1_26 = 0.65 
macro_f1_26 = 0.6251172613450174 

Epoch - 27 Train-Loss : 0.6743545435369015

Epoch - 27 Valid-Loss : 1.3139138150215148
micro_f1_27 = 0.665 
macro_f1_27 = 0.6492010840896288 

Epoch - 28 Train-Loss : 0.6281852993369103

Epoch - 28 Valid-Loss : 1.2631779575347901
micro_f1_28 = 0.655 
macro_f1_28 = 0.6394679647837542 

Epoch - 29 Train-Loss : 0.614271744787693

Epoch - 29 Valid-Loss : 1.2689494109153747
micro_f1_29 = 0.6675 
macro_f1_29 = 0.6483251054071488 
Overfitting detected

Epoch - 30 Train-Loss : 0.5880446746945381

Epoch - 30 Valid-Loss : 1.2500139951705933
micro_f1_30 = 0.675 
macro_f1_30 = 0.6635223192550559 

Epoch - 31 Train-Loss : 0.5571236357092857

Epoch - 31 Valid-Loss : 1.2781522488594055
micro_f1_31 = 0.675 
macro_f1_31 = 0.658042190179961 
Overfitting detected
Changed learning rate to 1.0000000000000002e-06
learning rate reduced..

Epoch - 32 Train-Loss : 0.5171430048346519

Epoch - 32 Valid-Loss : 1.227349283695221
micro_f1_32 = 0.68 
macro_f1_32 = 0.6611870051173456 

Epoch - 33 Train-Loss : 0.5046547463536263

Epoch - 33 Valid-Loss : 1.216420066356659
micro_f1_33 = 0.6775 
macro_f1_33 = 0.6610158843564417 

Epoch - 34 Train-Loss : 0.5073804606497287

Epoch - 34 Valid-Loss : 1.208642897605896
micro_f1_34 = 0.6725 
macro_f1_34 = 0.652671885905632 

Epoch - 35 Train-Loss : 0.490200080126524

Epoch - 35 Valid-Loss : 1.2173680901527404
micro_f1_35 = 0.665 
macro_f1_35 = 0.6476118027139698 
Overfitting detected
Changed learning rate to 1.0000000000000002e-06
learning rate re-reduced..

Epoch - 36 Train-Loss : 0.4955528971552849

Epoch - 36 Valid-Loss : 1.206921923160553
micro_f1_36 = 0.6825 
macro_f1_36 = 0.6698590056688051 

Epoch - 37 Train-Loss : 0.5016520632803441

Epoch - 37 Valid-Loss : 1.2060026836395263
micro_f1_37 = 0.675 
macro_f1_37 = 0.6613781890623994 

Epoch - 38 Train-Loss : 0.4825986383855343

Epoch - 38 Valid-Loss : 1.2028630948066712
micro_f1_38 = 0.69 
macro_f1_38 = 0.6766277496153655 

Epoch - 39 Train-Loss : 0.4819514149427414

Epoch - 39 Valid-Loss : 1.204647512435913
micro_f1_39 = 0.675 
macro_f1_39 = 0.6599921274116319 
Overfitting detected
training is terminating so as to prevent further overfitting
params = 2479150
params2 =  2479150
Experiment's attempt changed to : 3
