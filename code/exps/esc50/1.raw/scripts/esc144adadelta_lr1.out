/mnt/scratch_a/users/m/melissap/code/exps/esc50/1.raw/models.py:363: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = self.activation(x)
44100
(2000, 7)
audio_files length:2000
loadin waveforms..
features are loaded
cpu
model initialized...
attempt is already initialized
Experiment's _44100 attempt no_ : 5
Train started..

Epoch - 1 Train-Loss : 3.903449122905731

Epoch - 1 Valid-Loss : 3.887833385467529
micro_f1_1 = 0.04 
macro_f1_1 = 0.006022395185324499 

Epoch - 2 Train-Loss : 3.894170527458191

Epoch - 2 Valid-Loss : 3.887864294052124
micro_f1_2 = 0.055 
macro_f1_2 = 0.012402326571144843 
Overfitting detected

Epoch - 3 Train-Loss : 3.8928423810005186

Epoch - 3 Valid-Loss : 3.8979302406311036
micro_f1_3 = 0.0425 
macro_f1_3 = 0.006965377027247217 
Overfitting detected
Changed learning rate to 0.05
learning rate reduced..

Epoch - 4 Train-Loss : 3.8940582418441774

Epoch - 4 Valid-Loss : 3.889349412918091
micro_f1_4 = 0.05249999999999999 
macro_f1_4 = 0.010644162308193929 

Epoch - 5 Train-Loss : 3.881503939628601

Epoch - 5 Valid-Loss : 3.8892506980895996
micro_f1_5 = 0.0575 
macro_f1_5 = 0.011321413521160674 

Epoch - 6 Train-Loss : 3.884428858757019

Epoch - 6 Valid-Loss : 3.8887295532226562
micro_f1_6 = 0.055 
macro_f1_6 = 0.010060561117290817 

Epoch - 7 Train-Loss : 3.8787798929214476

Epoch - 7 Valid-Loss : 3.887994842529297
micro_f1_7 = 0.05249999999999999 
macro_f1_7 = 0.009797256097560976 

Epoch - 8 Train-Loss : 3.8785839819908143

Epoch - 8 Valid-Loss : 3.886708726882935
micro_f1_8 = 0.05249999999999999 
macro_f1_8 = 0.013355264867022987 

Epoch - 9 Train-Loss : 3.873259937763214

Epoch - 9 Valid-Loss : 3.8855820369720457
micro_f1_9 = 0.055 
macro_f1_9 = 0.0101400868551073 

Epoch - 10 Train-Loss : 3.875553078651428

Epoch - 10 Valid-Loss : 3.886423635482788
micro_f1_10 = 0.05249999999999999 
macro_f1_10 = 0.011313430420711973 
Overfitting detected
Changed learning rate to 0.05
learning rate re-reduced..

Epoch - 11 Train-Loss : 3.8760994482040405

Epoch - 11 Valid-Loss : 3.886455326080322
micro_f1_11 = 0.0625 
macro_f1_11 = 0.019686183381835556 
Overfitting detected
training is terminating so as to prevent further overfitting
params = 555138
Experiment's attempt changed to : 6
/mnt/scratch_a/users/m/melissap/code/exps/esc50/1.raw/models.py:363: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = self.activation(x)
44100
(2000, 7)
audio_files length:2000
loadin waveforms..
features are loaded
cpu
model initialized...
attempt is already initialized
Experiment's _44100 attempt no_ : 5
Train started..

Epoch - 1 Train-Loss : 3.907137372493744

Epoch - 1 Valid-Loss : 3.9083384609222414
micro_f1_1 = 0.0375 
macro_f1_1 = 0.009794076998753952 

Epoch - 2 Train-Loss : 3.9015221118927004

Epoch - 2 Valid-Loss : 3.9030046463012695
micro_f1_2 = 0.0625 
macro_f1_2 = 0.015477611425988238 

Epoch - 3 Train-Loss : 3.8918925499916077

Epoch - 3 Valid-Loss : 3.8944107913970947
micro_f1_3 = 0.045 
macro_f1_3 = 0.014382493883105878 

Epoch - 4 Train-Loss : 3.885226469039917

Epoch - 4 Valid-Loss : 3.8897913551330565
micro_f1_4 = 0.0475 
macro_f1_4 = 0.009262883985921087 

Epoch - 5 Train-Loss : 3.880888741016388

Epoch - 5 Valid-Loss : 3.886193885803223
micro_f1_5 = 0.055 
macro_f1_5 = 0.021659187494427766 

Epoch - 6 Train-Loss : 3.8712389349937437

Epoch - 6 Valid-Loss : 3.875584592819214
micro_f1_6 = 0.075 
macro_f1_6 = 0.03648811139810084 

Epoch - 7 Train-Loss : 3.8637810921669007

Epoch - 7 Valid-Loss : 3.867442083358765
micro_f1_7 = 0.10000000000000002 
macro_f1_7 = 0.054041138398165545 

Epoch - 8 Train-Loss : 3.8494842576980592

Epoch - 8 Valid-Loss : 3.8585630798339845
micro_f1_8 = 0.1025 
macro_f1_8 = 0.05793737198285079 

Epoch - 9 Train-Loss : 3.843424243927002

Epoch - 9 Valid-Loss : 3.848309555053711
micro_f1_9 = 0.1275 
macro_f1_9 = 0.06784951603145796 

Epoch - 10 Train-Loss : 3.8343971514701845

Epoch - 10 Valid-Loss : 3.8545924186706544
micro_f1_10 = 0.10749999999999998 
macro_f1_10 = 0.06120274111250659 
Overfitting detected

Epoch - 11 Train-Loss : 3.8300426030158996

Epoch - 11 Valid-Loss : 3.84565731048584
micro_f1_11 = 0.11 
macro_f1_11 = 0.061495896658045 

Epoch - 12 Train-Loss : 3.823113226890564

Epoch - 12 Valid-Loss : 3.844200620651245
micro_f1_12 = 0.1325 
macro_f1_12 = 0.07135036694139715 

Epoch - 13 Train-Loss : 3.8182669568061827

Epoch - 13 Valid-Loss : 3.842836256027222
micro_f1_13 = 0.12 
macro_f1_13 = 0.06959756207239608 

Epoch - 14 Train-Loss : 3.818421895503998

Epoch - 14 Valid-Loss : 3.842994518280029
micro_f1_14 = 0.1275 
macro_f1_14 = 0.06960806417181642 
Overfitting detected
Changed learning rate to 1.0000000000000002e-06
learning rate reduced..

Epoch - 15 Train-Loss : 3.810704381465912

Epoch - 15 Valid-Loss : 3.843049879074097
micro_f1_15 = 0.125 
macro_f1_15 = 0.0716354617255299 
Overfitting detected
Changed learning rate to 1.0000000000000002e-06
learning rate re-reduced..

Epoch - 16 Train-Loss : 3.8141421365737913

Epoch - 16 Valid-Loss : 3.844474754333496
micro_f1_16 = 0.1225 
macro_f1_16 = 0.07152783258720291 
Overfitting detected
training is terminating so as to prevent further overfitting
params = 555138
Experiment's attempt changed to : 7
