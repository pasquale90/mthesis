/mnt/scratch_a/users/m/melissap/code/exps/esc50/1.raw/models.py:363: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  x = self.activation(x)
22050
(2000, 7)
audio_files length:2000
loadin waveforms..
features are loaded
cpu
model initialized...
attempt is already initialized
Experiment's _22050 attempt no_ : 2
Train started..

Epoch - 1 Train-Loss : 3.9104623699188235

Epoch - 1 Valid-Loss : 3.901228151321411
micro_f1_1 = 0.05000000000000001 
macro_f1_1 = 0.011305808925136274 

Epoch - 2 Train-Loss : 3.9008808517456055

Epoch - 2 Valid-Loss : 3.8948396492004393
micro_f1_2 = 0.0575 
macro_f1_2 = 0.012265228132720392 

Epoch - 3 Train-Loss : 3.8931766653060915

Epoch - 3 Valid-Loss : 3.884665641784668
micro_f1_3 = 0.0425 
macro_f1_3 = 0.006191164658634538 

Epoch - 4 Train-Loss : 3.889253489971161

Epoch - 4 Valid-Loss : 3.8752458190917967
micro_f1_4 = 0.08 
macro_f1_4 = 0.02127138465650896 

Epoch - 5 Train-Loss : 3.8810100889205934

Epoch - 5 Valid-Loss : 3.8709893131256106
micro_f1_5 = 0.075 
macro_f1_5 = 0.020982952998380763 

Epoch - 6 Train-Loss : 3.869823181629181

Epoch - 6 Valid-Loss : 3.863881139755249
micro_f1_6 = 0.08 
macro_f1_6 = 0.020800928138269746 

Epoch - 7 Train-Loss : 3.8643786931037902

Epoch - 7 Valid-Loss : 3.8604569911956785
micro_f1_7 = 0.0825 
macro_f1_7 = 0.022355241490535603 

Epoch - 8 Train-Loss : 3.8632227182388306

Epoch - 8 Valid-Loss : 3.8588966941833496
micro_f1_8 = 0.09 
macro_f1_8 = 0.02618052104595826 

Epoch - 9 Train-Loss : 3.8559311628341675

Epoch - 9 Valid-Loss : 3.853123941421509
micro_f1_9 = 0.10000000000000002 
macro_f1_9 = 0.03136402765097169 

Epoch - 10 Train-Loss : 3.85096488237381

Epoch - 10 Valid-Loss : 3.856451168060303
micro_f1_10 = 0.09 
macro_f1_10 = 0.031226503405748684 
Overfitting detected

Epoch - 11 Train-Loss : 3.8469788336753847

Epoch - 11 Valid-Loss : 3.8546882247924805
micro_f1_11 = 0.095 
macro_f1_11 = 0.034966352191972916 

Epoch - 12 Train-Loss : 3.8500153756141664

Epoch - 12 Valid-Loss : 3.851673107147217
micro_f1_12 = 0.10000000000000002 
macro_f1_12 = 0.03585562862430641 

Epoch - 13 Train-Loss : 3.846094186306

Epoch - 13 Valid-Loss : 3.8497507572174072
micro_f1_13 = 0.1125 
macro_f1_13 = 0.04786964303516086 

Epoch - 14 Train-Loss : 3.8327388525009156

Epoch - 14 Valid-Loss : 3.8447680473327637
micro_f1_14 = 0.1225 
macro_f1_14 = 0.05346236288228519 

Epoch - 15 Train-Loss : 3.834632787704468

Epoch - 15 Valid-Loss : 3.846954107284546
micro_f1_15 = 0.1225 
macro_f1_15 = 0.05912051709110532 
Overfitting detected
Changed learning rate to 1.0000000000000002e-06
learning rate reduced..

Epoch - 16 Train-Loss : 3.828086576461792

Epoch - 16 Valid-Loss : 3.84120792388916
micro_f1_16 = 0.1325 
macro_f1_16 = 0.0656263360474524 

Epoch - 17 Train-Loss : 3.8243239665031434

Epoch - 17 Valid-Loss : 3.841315231323242
micro_f1_17 = 0.13 
macro_f1_17 = 0.06335916432424885 
Overfitting detected
Changed learning rate to 1.0000000000000002e-06
learning rate re-reduced..

Epoch - 18 Train-Loss : 3.8244338250160217

Epoch - 18 Valid-Loss : 3.8400891780853272
micro_f1_18 = 0.135 
macro_f1_18 = 0.06548009697937962 

Epoch - 19 Train-Loss : 3.8237657570838928

Epoch - 19 Valid-Loss : 3.8444280338287355
micro_f1_19 = 0.1325 
macro_f1_19 = 0.06272944950119624 
Overfitting detected
training is terminating so as to prevent further overfitting
params = 555138
Experiment's attempt changed to : 3
