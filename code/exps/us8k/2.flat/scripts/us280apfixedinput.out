80
csv containts 8732 rows and 8 columns.
fold no_1 contains 873 audiofiles
fold no_2 contains 888 audiofiles
fold no_3 contains 925 audiofiles
fold no_4 contains 990 audiofiles
fold no_5 contains 936 audiofiles
fold no_6 contains 823 audiofiles
fold no_7 contains 838 audiofiles
fold no_8 contains 806 audiofiles
fold no_9 contains 816 audiofiles
fold no_10 contains 837 audiofiles
All in all there are 8732 audio files found in 8k Urban Sound dataset folders
Index(['slice_file_name', 'fsID', 'start', 'end', 'salience', 'fold',
       'classID', 'class'],
      dtype='object')


column <class> became... <Class>
['air_conditioner', 'car_horn', 'children_playing', 'dog_bark', 'drilling', 'engine_idling', 'gun_shot', 'jackhammer', 'siren', 'street_music']
loadin mel-spectograms..
features are loaded
cpu
model initialized...
attempt is already initialized
Experiment's _80 attempt no_ : 1
Train started..

Epoch - 1 Train-Loss : 1.3163052252690424

Epoch - 1 Valid-Loss : 2.090397580826083
micro_f1_1 = 0.24731182795698925 
macro_f1_1 = 0.22155519800256643 

Epoch - 2 Train-Loss : 1.0376120945735121

Epoch - 2 Valid-Loss : 2.1459675085071024
micro_f1_2 = 0.2855436081242533 
macro_f1_2 = 0.24763722609072336 
Overfitting detected

Epoch - 3 Train-Loss : 0.8805953881868794

Epoch - 3 Valid-Loss : 2.175706230006053
micro_f1_3 = 0.3010752688172043 
macro_f1_3 = 0.255029379064305 
Overfitting detected
Changed learning rate to 1.0000000000000002e-06
learning rate reduced..

Epoch - 4 Train-Loss : 0.9359433913359503

Epoch - 4 Valid-Loss : 1.9983632623072238
micro_f1_4 = 0.3201911589008363 
macro_f1_4 = 0.27776812098712245 

Epoch - 5 Train-Loss : 0.8118485346562038

Epoch - 5 Valid-Loss : 1.9858444078181166
micro_f1_5 = 0.3213859020310633 
macro_f1_5 = 0.28087500607793314 

Epoch - 6 Train-Loss : 0.763170627394129

Epoch - 6 Valid-Loss : 1.9759689247326897
micro_f1_6 = 0.3237753882915173 
macro_f1_6 = 0.2824018924407179 

Epoch - 7 Train-Loss : 0.7260013579266152

Epoch - 7 Valid-Loss : 1.9699281144802645
micro_f1_7 = 0.32616487455197135 
macro_f1_7 = 0.2843710567917407 

Epoch - 8 Train-Loss : 0.6931446991271002

Epoch - 8 Valid-Loss : 1.9613027710872597
micro_f1_8 = 0.3345280764635603 
macro_f1_8 = 0.29305602025025623 

Epoch - 9 Train-Loss : 0.6642738108827264

Epoch - 9 Valid-Loss : 1.9600897348856414
micro_f1_9 = 0.33811230585424135 
macro_f1_9 = 0.29531526438926614 

Epoch - 10 Train-Loss : 0.6364560664200507

Epoch - 10 Valid-Loss : 1.951672350090963
micro_f1_10 = 0.34647550776583036 
macro_f1_10 = 0.30682076899738453 

Epoch - 11 Train-Loss : 0.616821026039582

Epoch - 11 Valid-Loss : 1.9487903462266694
micro_f1_11 = 0.3655913978494623 
macro_f1_11 = 0.3261796825647268 

Epoch - 12 Train-Loss : 0.5939003050464964

Epoch - 12 Valid-Loss : 1.9450080197353445
micro_f1_12 = 0.36917562724014336 
macro_f1_12 = 0.32952117560243466 

Epoch - 13 Train-Loss : 0.573216273522354

Epoch - 13 Valid-Loss : 1.9302621395432857
micro_f1_13 = 0.3811230585424134 
macro_f1_13 = 0.340320973267272 

Epoch - 14 Train-Loss : 0.557731623034443

Epoch - 14 Valid-Loss : 1.9238387890529498
micro_f1_14 = 0.3906810035842294 
macro_f1_14 = 0.34844012720056916 

Epoch - 15 Train-Loss : 0.5389158103901107

Epoch - 15 Valid-Loss : 1.918392093936727
micro_f1_15 = 0.3966547192353644 
macro_f1_15 = 0.35476485381123374 

Epoch - 16 Train-Loss : 0.521842245348953

Epoch - 16 Valid-Loss : 1.9034819014107847
micro_f1_16 = 0.39904420549581837 
macro_f1_16 = 0.3546815300688718 

Epoch - 17 Train-Loss : 0.5053906636729956

Epoch - 17 Valid-Loss : 1.895247612571346
micro_f1_17 = 0.40262843488649946 
macro_f1_17 = 0.35790239683732933 

Epoch - 18 Train-Loss : 0.4891909740557871

Epoch - 18 Valid-Loss : 1.8884446326545312
micro_f1_18 = 0.4121863799283154 
macro_f1_18 = 0.3669971444787228 

Epoch - 19 Train-Loss : 0.47410500447595993

Epoch - 19 Valid-Loss : 1.8765654852802964
micro_f1_19 = 0.4121863799283154 
macro_f1_19 = 0.3667453496571936 

Epoch - 20 Train-Loss : 0.4596856707974484

Epoch - 20 Valid-Loss : 1.8709227553009096
micro_f1_20 = 0.41696535244922334 
macro_f1_20 = 0.37131561420238546 

Epoch - 21 Train-Loss : 0.443409062532492

Epoch - 21 Valid-Loss : 1.8562988061791679
micro_f1_21 = 0.42532855436081235 
macro_f1_21 = 0.37846786434831103 

Epoch - 22 Train-Loss : 0.43308322291838897

Epoch - 22 Valid-Loss : 1.8435858934027285
micro_f1_22 = 0.43130227001194743 
macro_f1_22 = 0.38385337877802767 

Epoch - 23 Train-Loss : 0.4164202929598093

Epoch - 23 Valid-Loss : 1.8394102230067215
micro_f1_23 = 0.42532855436081235 
macro_f1_23 = 0.37807409726535307 

Epoch - 24 Train-Loss : 0.40466442456645085

Epoch - 24 Valid-Loss : 1.8322666663511822
micro_f1_24 = 0.42532855436081235 
macro_f1_24 = 0.37714580636941997 

Epoch - 25 Train-Loss : 0.39295594461964045

Epoch - 25 Valid-Loss : 1.8283487365023636
micro_f1_25 = 0.4265232974910394 
macro_f1_25 = 0.37825902322652655 

Epoch - 26 Train-Loss : 0.38320377663419647

Epoch - 26 Valid-Loss : 1.82046894121608
micro_f1_26 = 0.4336917562724014 
macro_f1_26 = 0.3848756597023625 

Epoch - 27 Train-Loss : 0.36937059239729414

Epoch - 27 Valid-Loss : 1.811441119773627
micro_f1_27 = 0.43130227001194743 
macro_f1_27 = 0.38061557667829726 

Epoch - 28 Train-Loss : 0.36090268533172415

Epoch - 28 Valid-Loss : 1.7935490190956114
micro_f1_28 = 0.4432497013142174 
macro_f1_28 = 0.38989603023511915 

Epoch - 29 Train-Loss : 0.34838781970183874

Epoch - 29 Valid-Loss : 1.7891386639941016
micro_f1_29 = 0.4444444444444444 
macro_f1_29 = 0.3914781696838826 

Epoch - 30 Train-Loss : 0.3374772739007098

Epoch - 30 Valid-Loss : 1.786373729440367
micro_f1_30 = 0.44086021505376344 
macro_f1_30 = 0.38672434780448256 

Epoch - 31 Train-Loss : 0.3219623252628203

Epoch - 31 Valid-Loss : 1.7818045048276796
micro_f1_31 = 0.44802867383512546 
macro_f1_31 = 0.39313048041114634 

Epoch - 32 Train-Loss : 0.31598191349128235

Epoch - 32 Valid-Loss : 1.7779355441690774
micro_f1_32 = 0.45041816009557945 
macro_f1_32 = 0.39592706934904076 

Epoch - 33 Train-Loss : 0.3054156449576004

Epoch - 33 Valid-Loss : 1.773992050000719
micro_f1_33 = 0.45280764635603343 
macro_f1_33 = 0.39724490452898664 

Epoch - 34 Train-Loss : 0.29352608320590984

Epoch - 34 Valid-Loss : 1.7744714920915299
micro_f1_34 = 0.45041816009557945 
macro_f1_34 = 0.39444806132507754 
Overfitting detected
Changed learning rate to 1.0000000000000002e-06
learning rate re-reduced..

Epoch - 35 Train-Loss : 0.2856443756807239

Epoch - 35 Valid-Loss : 1.7663012342338351
micro_f1_35 = 0.45997610513739545 
macro_f1_35 = 0.4034670698958399 

Epoch - 36 Train-Loss : 0.2801659205277461

Epoch - 36 Valid-Loss : 1.7651708429487891
micro_f1_36 = 0.45997610513739545 
macro_f1_36 = 0.40357633703613294 

Epoch - 37 Train-Loss : 0.268619455248009

Epoch - 37 Valid-Loss : 1.7666692912418356
micro_f1_37 = 0.45997610513739545 
macro_f1_37 = 0.4024787073417874 
Overfitting detected
training is terminating so as to prevent further overfitting
Traceback (most recent call last):
  File "/mnt/scratch_a/users/m/melissap/code/exps/us8k/2.flat/main.py", line 100, in <module>
    train.train(model, loss_fn, train_loader, valid_loader, 
  File "/mnt/scratch_a/users/m/melissap/code/exps/us8k/2.flat/train.py", line 124, in train
    genres_filename = store.genres_filename(expid,mode,exp_attempt.get_attempt())
TypeError: genres_filename() takes 2 positional arguments but 3 were given
